#LLM part of the robot for rpi and server
chat:
  network:
    RCV_CMD_IP: "0.0.0.0"
    RCV_CMD_PORT: 5006
    SEND_RPI_PORT: 5004
    SEND_PORT: 5008
    RCV_AUDIO_PORT: 5007
    BUFFER_SIZE: 16384
    AUTHORIZED_IPS: ["127.0.0.1", "xxx.xxx.xxx.xxx", "xxx.xxx.xxx.xxx", "xxx.xxx.xxx.xxx"]
    RASPI_ADDR: "xxx.xxx.xxx.xxx"
    NET_ADDR: "127.0.0.1"
  #models in use, vllm backend
  llms:
    sentence_embedder: "paraphrase-multilingual-MiniLM-L12-v2"
    spacy_model: "fr_core_news_lg"
    spacy_model_en: "en_core_web_lg"
    vllm_chat:
      #model: "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4"
      #model: "Qwen/Qwen3-30B-A3B-GPTQ-Int4"
      model: "JunHowie/Qwen3-14B-GPTQ-Int4"
      enable_chunked_prefill: true
      quantization: "gptq"
      max_model_len: 5000 
      max_num_batched_tokens: 32
      gpu_memory_utilization: 0.79
      block_size: 16
      max_num_seqs: 4
      device: "cuda"
      task: "generate"
      multi_step_stream_outputs: true
    searcher_max_tokens: 64
    summarizer_max_tokens: 1024
    memmorizer_max_tokens: 2048
    pokemoner_max_tokens: 8
    json_generator_max_tokens: 2048
    msg_queue_size: 50
  #meteo or localtion requests
  location:
    default_location: "your_city"
    default_timezone: "you_timezone"
    default_latitude: yy.yyyy
    default_longitude: yy.yyyy
  #meteo openweather API
  #key in environ variables
  weather:
    max_forecast_days: 5
    api_timeout: 5
  #pokemon requests
  pokemon:
    pokemon_list: "pokemon.txt"
    pokemon_list_en: "pokemon_en.txt"
    pokemon_phonetics: "pokemon_phonetics_fr.txt"
    pokemon_find_threshold: 91
  #long term memory, short term nad/or graph like networkx
  databases:
    knowledge_graph_path: "knowledge_graph.pkl"
    mem_path: "memory"
    chromadb_path: "chroma_db"
    ltm_collection_name: "long_term_memory"
    ltm_results_limit: 10
    importance: 0.5
    stm_history_limit: 5
  general:
    model_name: "Mars"
    lang: "fr"
    unprivileged_user: "your_username"
  #wiki API request
  wikipedia:
    wiki_sentence_search_nb: 3
    reponse_timeout: 10
    summary_size: 10 #number of sentences

whispercpp_server:
  general:
    lang: "fr"
  model:
    whisper_model: "large-v3-turbo-q8_0"
    threads: 12
    keyword: "mars"
    phonetic_variants: ["marsse", "marse", "marce"]
    startup_sound: "./sounds/PS1_startup.wav"
    whisper_cli: "/root/whisper.cpp/build/bin/whisper-cli"
    whisper_stream: "/root/whisper.cpp/build/bin/whisper-stream"
    whisper_model_path: "/root/whisper.cpp/models"  
    piper_path: "/opt/piper/piper/piper"
    piper_voice_path: "/opt/piper/piper/voices/fr_FR-upmc-medium.onnx"
    tmpfs_dir: "/dev/shm/whisper_stream"
    tts_engine: "piper-tts"
    porcupine_path: "./porcupine/porcupine_params_fr.pv"
    porcupine_keyword_path: "./porcupine/Ok-Mars_fr_linux_v3_0_0.ppn"
  audio:
    sample_rate: 16000 #shoudl not be changed
    chunk_size: 1024
    buffer_time: 2.0 #4.0
    min_cmd_length: 1.0
    min_audio_level: 1000
    silence_threshold: 300
    activity_threshold: 500
    keyword_sensitivity: 0.75
    client_audio_window: 2.0
    EOS: 1.2 #in seconds - silence to detect EOS
    virtual_mic_name: "VirtualMIC"
    stream_buffer_size: 1024
    channels: 1 #shoudl not be changed
    period_size: 1024 #512
    ignore_own: 3.0 #ignore own audio for X seconds
    format: alsaaudio.PCM_FORMAT_S16_LE #have to get the correct type
  network:
    LISTEN_IP: "0.0.0.0"
    AUTHORIZED_IPS: ["127.0.0.1", "xxx.xxx.xxx.xxx"]
    SEND_RPI_PORT: 5020
    LISTEN_RPI_PORT: 5011
    SEND_CHAT_PORT: 5006
    RCV_END_SIGNAL: 5008
    SEND_CHAT_COMPLETION: 5007
    STATUS_REQUEST_PORT: 5005
    RCV_CHAT_CMD_PORT: 5004
    MAX_UDP_SIZE: 1400
    CHAT_ADDR: "127.0.0.1"
    RPI_IP: "xxx.xxx.xxx.xxx"
    rcv_buffer_size: 4096 #8192
    server_reset_delay: 90

#all related to vision like MiDaS or yolo or BLIP
#and related sensors
vision:
  general:
    device: "cuda"
  network:
    LISTEN_ADDR: "0.0.0.0"
    RPI_IP: "xxx.xxx.xxx.xxx"
    RCV_IMG_PORT: 5500
    WEB_BROWSER_PORT: 8080
    MAX_UDP_SIZE: 1472
    BUFFER_SIZE: 2944
    PAN_TILT_LST_PORT: 5001
  depth:
    model: "Intel/dpt-swinv2-base-384"
  pantilt:
    config_file: "/panTilt_config.yaml"
  segmentation:
    model:  ""
  sensors:
    aceinna: ""
    camera_height: 480 
    camera_width: 640
    jpg_quality: 90
    arduino: ""
