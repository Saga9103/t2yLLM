#LLM part of the robot for rpi and server
chat:
  network:
    RCV_CMD_IP: "0.0.0.0" # listens on all interfaces by default
    RCV_CMD_PORT: 5006
    SEND_DISPATCH_PORT: 5004 # same as RCV_CHAT_CMD_PORT
    SEND_PORT: 5008
    RCV_AUDIO_PORT: 5007
    BUFFER_SIZE: 16384
    AUTHORIZED_IPS: ["127.0.0.1", "192.168.2.203"] # should be changed to add raspi and servers addr ["127.0.0.1", "xxx.xxx.xxx.xxx", "xxx.xxx.xxx.xxx", "xxx.xxx.xxx.xxx"]
    # those should be VoiceEngine_server_IP, AssistantEngine_server_ip, Raspberry Pi IP
    RASPI_ADDR: "192.168.2.203" #"127.0.0.1" # replace by your raspberry Pi IP
    NET_ADDR: "127.0.0.1"
    hmac_enabled: True
  #models in use, vllm backend
  llms:
    sentence_embedder: "paraphrase-multilingual-MiniLM-L12-v2"
    spacy_model: "fr_core_news_lg"
    spacy_model_en: "en_core_web_lg"
    vllm_chat:
      #model: "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4"
      #model: "Qwen/Qwen3-30B-A3B-GPTQ-Int4"
      model: "JunHowie/Qwen3-14B-GPTQ-Int4"
      enable_chunked_prefill: true
      quantization: "gptq"
      max_model_len: 5000 
      max_num_batched_tokens: 32
      gpu_memory_utilization: 0.79
      block_size: 16
      max_num_seqs: 4
      device: "cuda"
      task: "generate"
      multi_step_stream_outputs: true
    searcher_max_tokens: 64
    summarizer_max_tokens: 1024
    memmorizer_max_tokens: 2048
    pokemoner_max_tokens: 8
    json_generator_max_tokens: 2048 # max tokens for vLLM output
    msg_queue_size: 50
  #meteo or localtion requests
  location:
    default_location: "your_city" #replace for a default city
    default_timezone: "you_timezone" # replace by your timezone
    default_latitude: 1.1111 # yy.yyyy
    default_longitude: 2.2222 # yy.yyyy
  #meteo openweather API
  #key in environ variables
  weather:
    max_forecast_days: 5 #max for openweather
    api_timeout: 5
  #pokemon requests
  pokemon:
    # should not be touched
    pokemon_list_fr: "pokemon_fr.txt"
    pokemon_list_en: "pokemon_en.txt"
    pokemon_phonetics: "pokemon_phonetics_fr.txt"
    pokemon_find_threshold: 91
  #long term memory, short term nad/or graph like networkx
  databases:
    #shoudl not be touched
    knowledge_graph_path: "knowledge_graph.pkl"
    mem_path: "memory"
    chromadb_path: "chroma_db"
    ltm_collection_name: "long_term_memory"
    ltm_results_limit: 10
    importance: 0.5 #irrelevant atm
    stm_history_limit: 5 #max of memories to consider
  general:
    model_name: "Mars" # should be modified according to your custom keyword
    lang: "fr" # atm only en and fr are functional
    unprivileged_user: "your_username" # your linux unpriviledged user name in order to run easpeak-ng
    # can be deactivated for faster processing
    activate_memory: True # it wont save and process for chromadb if set to false
    web_enabled: True # toggles on or off web browsing (wikipedia only)
  #wiki API request
  wikipedia:
    wiki_sentence_search_nb: 3
    reponse_timeout: 10
    summary_size: 10 #number of sentences
  plugins:
    # in the plugins directory, should be formatted as :
    # {"name of the module file" : "name of the class" }
    plugins_dict: {"date":"DateAPI","time":"TimeAPI","pokemon":"PokeAPI", "wikipedia":"WikiAPI", "weather":"WeatherAPI", "yeelightRemote":"XiaomiLightAPI"}
    enabled_plugins: ["pokemon", "date", "time", "weather", "wikipedia", "yeelightRemote"]

faster_whisper:
  general:
    lang: "fr" # only en and fr are functional atm
  model:
    whisper_model: "large-v3-turbo-q8_0"
    threads: 12
    keyword: "ok mars"
    phonetic_variants: ["marsse", "marse", "marce"] #should be changed according to your language
    # not relevant atm :
    piper_path: "piper" #"/opt/piper/piper/piper"
    piper_fr_voice_path: "config/piper/fr/fr_FR-upmc-medium.onnx" #"/opt/piper/piper/voices/fr_FR-upmc-medium.onnx"
    piper_en_voice_path: "config/piper/en/en_US-hfc_female-medium.onnx"
    # can be changed accorded to your needs :
    tmpfs_dir: "/dev/shm/whisper_stream"
    tts_engine: "piper-tts"
    # the porcupine files should be downloaded directly from porcupine
    # according to your language and your keyword of choice, a composed keyword is
    # way easier
    porcupine_path: "porcupine_params_fr.pv"
    porcupine_keyword_path: "Ok-Mars_fr_linux_v3_0_0.ppn"
  audio:
    sample_rate: 16000 #should not be changed
    chunk_size: 1024 # should not be changed
    buffer_time: 2.0 #4.0
    min_cmd_length: 1.0
    min_audio_level: 1000
    silence_threshold: 300
    activity_threshold: 500
    keyword_sensitivity: 0.75
    client_audio_window: 2.0
    EOS: 1.2 # in seconds - silence to detect EOS
    virtual_mic_name: "VirtualMIC"
    stream_buffer_size: 1024
    channels: 1 #shoudl not be changed
    period_size: 1024 #512
    ignore_own: 3.0 #ignore own audio for X seconds
    format: alsaaudio.PCM_FORMAT_S16_LE #have to get the correct type
  network:
    LISTEN_IP: "0.0.0.0"
    AUTHORIZED_IPS: ["127.0.0.1", "192.168.2.203"] # should be changed by adding your raspberry Pi addr ["127.0.0.1", "xxx.xxx.xxx.xxx"]
    SEND_RPI_PORT: 5020 # this port should be opened on your raspberry Pi
    LISTEN_RPI_PORT: 5011 # recv from raspberry PI
    SEND_CHAT_PORT: 5006 # send to  AssistantEngine
    RCV_END_SIGNAL: 5008 # recv from AssistantEngine
    SEND_CHAT_COMPLETION: 5007
    STATUS_REQUEST_PORT: 5005
    RCV_CHAT_CMD_PORT: 5004 #same as SEND_DISPATCH_PORT
    MAX_UDP_SIZE: 1400 # according to your MTU 1472 or lower
    CHAT_ADDR: "127.0.0.1" # adress of the AssistantEngine on your local network
    RPI_IP: "192.168.2.203" #"127.0.0.1" # should be changed to your raspberry Pi IP"xxx.xxx.xxx.xxx"
    rcv_buffer_size: 4096 #8192
    server_reset_delay: 90 # time after which the server reset its state else it will hang indefinitly waiting for AssitantEngine if it fails
    hmac_enabled: True

#all related to vision like MiDaS or yolo or BLIP
#and related sensors
# not implemented atm
vision:
  general:
    device: "cuda"
  network:
    LISTEN_ADDR: "0.0.0.0"
    RPI_IP: 127.0.0.1 # should be changed to your raspberry IP"xxx.xxx.xxx.xxx"
    RCV_IMG_PORT: 5500
    WEB_BROWSER_PORT: 8080
    MAX_UDP_SIZE: 1472
    BUFFER_SIZE: 2944
    PAN_TILT_LST_PORT: 5001
  depth:
    model: "Intel/dpt-swinv2-base-384"
  pantilt:
    config_file: "/panTilt_config.yaml"
  segmentation:
    model:  ""
  sensors:
    aceinna: ""
    camera_height: 480 
    camera_width: 640
    jpg_quality: 90
    arduino: ""
